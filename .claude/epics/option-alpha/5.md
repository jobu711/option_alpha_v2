---
name: Pipeline orchestrator
status: open
created: 2026-02-11T00:53:50Z
updated: 2026-02-11T00:55:00Z
github: https://github.com/jobu711/option_alpha_v2/issues/5
depends_on: [4, 7, 10, 11, 2]
parallel: false
conflicts_with: []
---

# Task: Pipeline orchestrator

## Description
Build the pipeline orchestrator that runs all scan phases in sequence (data fetch -> scoring -> catalysts -> options -> AI debate -> persist), reports progress, handles partial failures gracefully, and logs phase timing. This wires together all the individual modules into a complete scan pipeline.

## Acceptance Criteria
- [ ] `pipeline/orchestrator.py` executes phases in order: data -> scoring -> catalysts -> options -> AI -> persist
- [ ] `pipeline/progress.py` defines progress model: phase name, status, percentage, ticker count, elapsed time
- [ ] Progress callback system: orchestrator accepts a callable for progress updates (used by WebSocket later)
- [ ] Partial failure handling: if a phase partially fails (e.g., some tickers fail), continue with available data
- [ ] Phase timing: log start/end/duration for each phase
- [ ] Configurable: number of top candidates for options (default 50) and AI debate (default 10)
- [ ] Returns complete ScanResult with all ticker scores, options recs, and AI theses
- [ ] Unit tests with mocked phase modules verifying orchestration order and failure handling

## Technical Details
- Orchestrator is an async class that takes config and phase modules as dependencies
- Each phase returns a result object; orchestrator passes results forward through the chain
- Progress updates use a simple callback pattern: `async def on_progress(phase: str, pct: float, msg: str)`
- Partial failure: wrap each ticker processing in try/except, collect errors, continue
- Phase timing via `time.perf_counter()` with results stored in ScanResult metadata
- Filter chain: all tickers -> scored -> top 50 for options -> top 10 for AI debate

## Dependencies
- [ ] Task 001 (data layer)
- [ ] Task 002 (scoring engine)
- [ ] Task 003 (catalysts & options)
- [ ] Task 004 (AI debate)
- [ ] Task 005 (persistence for storing results)

## Effort Estimate
- Size: M
- Hours: 5-6
- Parallel: false (depends on all prior tasks)

## Definition of Done
- [ ] Code implemented
- [ ] Tests written and passing
- [ ] Full pipeline runs end-to-end with mocked externals
