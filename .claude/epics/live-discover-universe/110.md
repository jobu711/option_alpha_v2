---
name: Create core discovery engine module
status: open
created: 2026-02-14T15:56:05Z
updated: 2026-02-14T15:59:30Z
github: https://github.com/jobu711/option_alpha_v2/issues/110
depends_on: [108]
parallel: false
conflicts_with: []
---

# Task: Create core discovery engine module

## Description
Create `src/option_alpha/data/discovery.py` — the core discovery engine (~250 lines). This module fetches the CBOE optionable securities CSV, validates candidates via yfinance, manages a failure cache, detects stale tickers, and records run history. It reuses existing `universe_service` functions and adapts the `_filter_via_yfinance` batch pattern.

## Acceptance Criteria
- [ ] `data/discovery.py` created with 3 public functions and 5 internal helpers
- [ ] `run_discovery(conn, settings, on_progress)` executes the full pipeline: fetch → dedup → validate → add → detect stale → record
- [ ] `should_run_discovery(conn, settings)` returns True/False based on `universe_refresh_interval_days`
- [ ] `get_last_discovery_run(conn)` returns most recent completed run as dict or None
- [ ] CBOE CSV parsing filters non-equity symbols (index options `$SPX`, warrants `SPAK+`, units with `.`)
- [ ] yfinance validation uses batched `yf.download(period="5d")` with MultiIndex parsing
- [ ] Failed symbols cached in `discovery_failures` (skipped within TTL, re-validated after expiry)
- [ ] New tickers added via `universe_service.add_tickers(conn, symbols, tags=["auto-discovered"], source="discovered")`
- [ ] Stale tickers deactivated via `universe_service.toggle_ticker(conn, symbol, active=False)`
- [ ] Run stats recorded in `discovery_runs` table (including error cases)
- [ ] `DiscoveryResult` Pydantic model returned with counts

## Technical Details

### Public API
```python
class DiscoveryResult(BaseModel):
    cboe_fetched: int = 0
    candidates_checked: int = 0
    new_added: int = 0
    stale_deactivated: int = 0
    failures_cached: int = 0

async def run_discovery(conn, settings=None, on_progress=None) -> DiscoveryResult
def should_run_discovery(conn, settings=None) -> bool
def get_last_discovery_run(conn) -> dict | None
```

### Internal Pipeline (called by `run_discovery`)
1. **`_fetch_cboe_optionable(url)`** — `httpx.get()` + `csv.DictReader`, filter: `symbol.isalpha() and 1 <= len(symbol) <= 5`
2. **Dedup** — subtract `get_full_universe(conn)` + `_get_cached_failures(conn, ttl_hours)`
3. **`_validate_via_yfinance(candidates, settings)`** — batched download, MultiIndex parsing (adapted from `universe.py:151-211`), returns `(passed_list, failed_list)`
4. **`_cache_failures(conn, failed, reason)`** — INSERT OR REPLACE into `discovery_failures`
5. **Persist** — `universe_service.add_tickers(conn, symbols, tags=["auto-discovered"], source="discovered")`
6. **`_detect_stale_tickers(conn, threshold_days)`** — SQL query for old NULL or old `last_scanned_at`, deactivate via `toggle_ticker()`
7. **Record run** — UPDATE `discovery_runs` with stats

### Key reused functions
- `universe_service.get_full_universe(conn)` — dedup
- `universe_service.add_tickers(conn, symbols, tags, source)` — insert
- `universe_service.toggle_ticker(conn, symbol, active)` — deactivate (SAVEPOINT safety)

### Files affected
- `src/option_alpha/data/discovery.py` (CREATE — ~250 lines)

## Dependencies
- [ ] Task 108 (config settings + migration tables must exist)

## Effort Estimate
- Size: L
- Hours: 4
- Parallel: false (depends on 108, blocks 111)

## Definition of Done
- [ ] Code implemented
- [ ] Module imports cleanly
- [ ] All public functions have type hints
- [ ] Error handling records failures in `discovery_runs`
- [ ] Graceful fallback on CBOE fetch failure or yfinance errors
